{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrent execution\n",
    "\n",
    "The two main modules in Python Standard Library for parallelizing code are `threading` and `multiprocessing`. When deciding between the two, you should ask yourself: what kind of program are you trying to paralellize?\n",
    "* I/O bound program -> `threading`\n",
    "* CPU bound program -> `multiprocessing`\n",
    "\n",
    "## `threading`\n",
    "\n",
    "A thread is a separate flow of execution. This means that your program will have multiple things happening at once. But for most Python implementations the different threads do not actually execute at the same time: they merely appear to. In CPython, multi-threading is supported by introducing the Global Interpreter Lock (GIL) which to prevent multiple threads from accessing the same Python object simultaneously. Only one thread can hold the GIL at a time, one thread must wait for another thread to release the GIL before running.\n",
    "\n",
    "![Multithreading GIL](img/multithreading.png \"Multithreading GIL\")\n",
    "\n",
    "### Using `threading` module\n",
    "\n",
    "#### `threading.Thread` class\n",
    "* Represents an activity that is run in a separate thread of control\n",
    "* Activity can be specified by passing a callable to constructor or by overriding run() method in a subclass\n",
    "* Activity should be started by calling start() method of Thread instance\n",
    "* Threads can be named by setting `name` attribute\n",
    "* `start()` – Starts thread activity. Can be called only one time for a thread. It launches threads’s `run()` method in a separate thread of control\n",
    "* `run()` – Method representind threads’s activity. Defaults to callable passed in constructor as `target` parameter\n",
    "* `join([timeout])` – Blocking call that waits for specific thread to terminate\n",
    "* `is_alive()` – Queries thread status. Returns `True` unitl `run()` method terminates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread Thread-5 (func) alive status: True\n",
      "Total no of threads: 9\n",
      "Thread Thread-6 (func) alive status: True\n",
      "Total no of threads: 10\n",
      "Thread Thread-7 (func) alive status: True\n",
      "Total no of threads: 11\n",
      "Thread Thread-8 (func) alive status: True\n",
      "Total no of threads: 12\n",
      "Thread Thread-9 (func) alive status: True\n",
      "Total no of threads: 13\n",
      "Finished execution from thread 1Finished execution from thread 3\n",
      "Finished execution from thread 5\n",
      "Finished execution from thread 2\n",
      "\n",
      "Finished execution from thread 4\n",
      "Total time: 3.0063438416\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def func(nr):\n",
    "    time.sleep(3)\n",
    "    print(f\"Finished execution from thread {nr}\")\n",
    "\n",
    "\n",
    "time_start = time.time()\n",
    "threads = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    t = threading.Thread(target=func, args=(i, ))\n",
    "    threads.append(t)\n",
    "    t.start()  # target(*args)\n",
    "    \n",
    "    print(f'Thread {t.name} alive status: {t.is_alive()}')\n",
    "\n",
    "    count = threading.active_count()\n",
    "    print(f\"Total no of threads: {count}\")\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "time_end = time.time()\n",
    "total_time = time_end - time_start\n",
    "print(f'Total time: {total_time:.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `multiprocessing`\n",
    "\n",
    "Multiprocessing allows you to create programs that can run concurrently (bypassing the GIL) and use the entirety of your CPU core. Though it is fundamentally different from the threading library, the syntax is quite similar. The multiprocessing library gives each process its own Python interpreter and each their own GIL.\n",
    "\n",
    "Because of this, the usual problems associated with threading (such as data corruption and deadlocks) are no longer an issue. Since the processes don't share memory, they can't modify the same memory concurrently.\n",
    "\n",
    "If when using `threads` _how not to share_ is a problem (the memory space is common to all running threads of a certain process), when using `process` _how to share_ becomes a problem to solve (all process have their own copy of the initial parent process memory; what one changes, the other would not be able to see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 doubled to 20 by: Process-2\n",
      "5 doubled to 10 by: Process-1\n",
      "25 doubled to 50 by: Process-5\n",
      "20 doubled to 40 by: Process-4\n",
      "15 doubled to 30 by: Process-3\n",
      "Total execution time (parallel): 0.3718290329\n",
      "5 doubled to 10 by: MainProcess\n",
      "10 doubled to 20 by: MainProcess\n",
      "15 doubled to 30 by: MainProcess\n",
      "20 doubled to 40 by: MainProcess\n",
      "25 doubled to 50 by: MainProcess\n",
      "Total execution time (serial): 0.9248859882\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, current_process\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "def doubler(nr):\n",
    "    \"\"\"\n",
    "    A doubling function that can be used by a process\n",
    "    \"\"\"\n",
    "    # Mock time-consuming processing:\n",
    "    x = 0\n",
    "    for i in range(1000000):\n",
    "        x += random.randint(1, 10)\n",
    "\n",
    "    result = nr * 2\n",
    "    proc_name = current_process().name\n",
    "    print('{} doubled to {} by: {}'.format(nr, result, proc_name))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 15, 20, 25]\n",
    "    procs = []\n",
    "\n",
    "    time0 = time.time()\n",
    "    for number in numbers:\n",
    "        proc = Process(target=doubler, args=(number,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    "\n",
    "    for proc in procs:\n",
    "        proc.join()\n",
    "\n",
    "    time1 = time.time()\n",
    "    print(f'Total execution time (parallel): {time1-time0:.10f}')\n",
    "\n",
    "    time0 = time.time()\n",
    "\n",
    "    for number in numbers:\n",
    "        doubler(number)\n",
    "\n",
    "    time1 = time.time()\n",
    "    print(f'Total execution time (serial): {time1 - time0:.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since processes are still suitable for I/O - let's see an example of I/O operations performed:\n",
    "- sequentially\n",
    "- concurrently using threads\n",
    "- concurrently using processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial result: [50156, 9489, 78375, 8855, 19542, 19518, 8625]\n",
      "Execution time: 5.8237507343\n",
      "\n",
      "Concurrent result (threads): [50156, 9489, 78375, 8855, 19542, 19518, 8625]\n",
      "Execution time: 1.3206427097\n",
      "\n",
      "Concurrent result (processes): [50156, 9489, 78375, 8855, 19542, 19518, 8625]\n",
      "Execution time: 1.2490136623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from multiprocessing import Pool as ProcessPool\n",
    "from urllib.request import urlopen\n",
    "import time\n",
    "\n",
    "\n",
    "def get_url_resp(url):\n",
    "    resp = urlopen(url)\n",
    "    return len(resp.read())\n",
    "\n",
    "\n",
    "urls = [\n",
    "    'http://www.python.org',\n",
    "    'http://www.python.org/about/',\n",
    "    'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html',\n",
    "    'http://www.python.org/doc/',\n",
    "    'http://www.python.org/download/',\n",
    "    'http://www.python.org/getit/',\n",
    "    'http://www.python.org/community/',\n",
    "]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    d1 = time.time()\n",
    "    syncres = [get_url_resp(url) for url in urls]\n",
    "    # list(map(get_url_resp, urls))\n",
    "    d2 = time.time()\n",
    "    print(f'Serial result: {syncres}\\nExecution time: {d2 - d1:.10f}\\n')\n",
    "\n",
    "    d1 = time.time()\n",
    "    # make the Pool of thread workers\n",
    "    pool = ThreadPool(7)\n",
    "\n",
    "    # open the urls in their own threads\n",
    "    # and return the results\n",
    "    asyncres = pool.map(get_url_resp, urls)\n",
    "\n",
    "    # close the pool and wait for the workers to finish\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    d2 = time.time()\n",
    "\n",
    "    print(f'Concurrent result (threads): {asyncres}\\nExecution time: {d2 - d1:.10f}\\n')\n",
    "\n",
    "    d1 = time.time()\n",
    "    # make the Pool of process workers\n",
    "    pool = ProcessPool(7)\n",
    "\n",
    "    # open the urls in their own processes\n",
    "    # and return the results\n",
    "    asyncres = pool.map(get_url_resp, urls)\n",
    "\n",
    "    # close the pool and wait for the work to finish\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    d2 = time.time()\n",
    "\n",
    "    print(f'Concurrent result (processes): {asyncres}\\nExecution time: {d2 - d1:.10f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `concurrent.futures` — Launching parallel tasks\n",
    "\n",
    "The `concurrent.futures` module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "### ThreadPoolExecutor\n",
    "\n",
    "`ThreadPoolExecutor` is used for managing a pool of threads. It is suitable for I/O-bound tasks, as threads can run concurrently, and efficiently handle multiple tasks, such as network requests or file I/O.\n",
    "\n",
    "#### Example: Using ThreadPoolExecutor\n",
    "\n",
    "```python\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def io_bound_task(seconds):\n",
    "    print(f\"Sleeping for {seconds} second(s)...\")\n",
    "    time.sleep(seconds)\n",
    "    return f\"Slept for {seconds} second(s)\"\n",
    "\n",
    "# Create a ThreadPoolExecutor with a pool of 3 threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    # List of tasks to be run concurrently\n",
    "    tasks = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    # Submit tasks to the executor\n",
    "    futures = [executor.submit(io_bound_task, t) for t in tasks]\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(future.result())\n",
    "```\n",
    "\n",
    "### ProcessPoolExecutor\n",
    "\n",
    "`ProcessPoolExecutor` is used for managing a pool of processes. It is suitable for CPU-bound tasks, as processes can run on multiple cores, thus parallelizing the computation.\n",
    "\n",
    "#### Example: Using ProcessPoolExecutor\n",
    "\n",
    "```python\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "def cpu_bound_task(number):\n",
    "    print(f\"Computing factorial of {number}...\")\n",
    "    result = 1\n",
    "    for i in range(2, number + 1):\n",
    "        result *= i\n",
    "    return result\n",
    "\n",
    "# Create a ProcessPoolExecutor with a pool of 3 processes\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "    # List of tasks to be run concurrently\n",
    "    tasks = [10, 20, 30, 40, 50]\n",
    "    \n",
    "    # Submit tasks to the executor\n",
    "    futures = [executor.submit(cpu_bound_task, t) for t in tasks]\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        print(f\"Factorial computed: {future.result()}\")\n",
    "```\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **ThreadPoolExecutor** is ideal for I/O-bound tasks due to its use of threads.\n",
    "2. **ProcessPoolExecutor** is ideal for CPU-bound tasks due to its use of processes.\n",
    "3. Both executors manage a pool of workers, allowing you to submit multiple tasks which are then distributed among the available workers.\n",
    "4. Use `executor.submit(function, *args, **kwargs)` to submit tasks to the executor.\n",
    "5. Use `concurrent.futures.as_completed(futures)` to process the results as they complete.\n",
    "\n",
    "### Error Handling\n",
    "\n",
    "Both executors provide mechanisms to handle errors gracefully. You can wrap your task functions in try-except blocks or use the `future.result()` method to raise exceptions if they occurred during execution.\n",
    "\n",
    "#### Example: Error Handling\n",
    "\n",
    "```python\n",
    "import concurrent.futures\n",
    "\n",
    "def task_with_error(x):\n",
    "    if x == 3:\n",
    "        raise ValueError(\"An error occurred with input 3\")\n",
    "    return x * 2\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    tasks = [1, 2, 3, 4, 5]\n",
    "    futures = [executor.submit(task_with_error, t) for t in tasks]\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            print(f\"Result: {result}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "```\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Try out different strategies presented above to speed up execution for [process_files.py](./code/process_files.py). Compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
